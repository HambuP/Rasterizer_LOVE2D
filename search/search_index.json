{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"3D Software Rasterizer","text":"<p>A simple 3D software rasterizer built from scratch in Lua using L\u00d6VE2D. No GPU acceleration\u2014just pure CPU rendering to understand how 3D graphics really work.</p> <p></p>"},{"location":"#characteristics","title":"Characteristics","text":"<p>This rasterizer implements fundamental 3D rendering algorithms from scratch:</p> <ul> <li>Triangle rasterization using edge functions and barycentric coordinates</li> <li>Perspective projection with configurable field of view</li> <li>Z-buffering for correct depth sorting</li> <li>Perspective-correct interpolation for depth values</li> <li>FPS camera with mouse look (yaw/pitch) and WASD movement</li> <li>3D transformations with rotation matrices</li> </ul>"},{"location":"#requirements-controls","title":"Requirements &amp; Controls","text":""},{"location":"#requirements","title":"Requirements","text":"<ul> <li>L\u00d6VE2D 11.3 or higher</li> <li>Lua 5.1+</li> </ul>"},{"location":"#running","title":"Running","text":"<pre><code>git clone https://github.com/HambuP/Rasterizador_LOVE2D.git\ncd Rasterizador_LOVE2D\nlove lua/\n</code></pre>"},{"location":"#controls","title":"Controls","text":"<ul> <li>Mouse: Look around</li> <li>W/A/S/D: Move forward/left/backward/right</li> <li>ESC: Quit</li> </ul>"},{"location":"#explanation","title":"Explanation","text":"<ul> <li> <p>Simple Rasterization in LOVE</p> <p>Learn how triangle rasterization works in L\u00d6VE2D</p> </li> <li> <p>Basics of 3D Projection</p> <p>Understand perspective projection and coordinate transformations</p> </li> <li> <p>Camera and Movement</p> <p>Implement FPS-style camera controls with mouse and keyboard</p> </li> <li> <p>Z-Buffer</p> <p>Solve visibility problems with depth buffering</p> </li> </ul>"},{"location":"api_vectores/","title":"API: M\u00f3dulo de Vectores","text":"<p>Documentaci\u00f3n completa del m\u00f3dulo <code>vectors.lua</code> que implementa operaciones de \u00e1lgebra lineal para gr\u00e1ficos 3D.</p>"},{"location":"api_vectores/#importar-el-modulo","title":"Importar el M\u00f3dulo","text":"<pre><code>local vec = require(\"vectors\")\n</code></pre>"},{"location":"api_vectores/#operaciones-vectoriales","title":"Operaciones Vectoriales","text":""},{"location":"api_vectores/#veccrear","title":"<code>vec.crear()</code>","text":"<p>Crea un vector nulo (origen).</p> <p>Retorna: <code>{0, 0, 0}</code></p> <p>Ejemplo: <pre><code>local v = vec.crear()\n-- v = {0, 0, 0}\n</code></pre></p>"},{"location":"api_vectores/#vecdotvec1-vec2","title":"<code>vec.dot(vec1, vec2)</code>","text":"<p>Calcula el producto punto (dot product) entre dos vectores 3D.</p> <p>Par\u00e1metros:</p> <ul> <li><code>vec1</code>: Vector 3D <code>{x, y, z}</code></li> <li><code>vec2</code>: Vector 3D <code>{x, y, z}</code></li> </ul> <p>Retorna: N\u00famero (escalar)</p> <p>F\u00f3rmula:</p> \\[ \\mathbf{a} \\cdot \\mathbf{b} = a_x b_x + a_y b_y + a_z b_z \\] <p>Ejemplo: <pre><code>local a = {1, 0, 0}\nlocal b = {0, 1, 0}\nlocal resultado = vec.dot(a, b)\n-- resultado = 0 (vectores perpendiculares)\n\nlocal c = {3, 4, 0}\nlocal d = {1, 0, 0}\nlocal resultado2 = vec.dot(c, d)\n-- resultado2 = 3\n</code></pre></p> <p>Casos de uso:</p> <ul> <li>Calcular el \u00e1ngulo entre dos vectores: \\(\\cos(\\theta) = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{|\\mathbf{a}||\\mathbf{b}|}\\)</li> <li>Determinar si dos vectores son perpendiculares: \\(\\mathbf{a} \\cdot \\mathbf{b} = 0\\)</li> <li>Proyecci\u00f3n de un vector sobre otro</li> </ul>"},{"location":"api_vectores/#vecnormalizevec","title":"<code>vec.normalize(vec)</code>","text":"<p>Normaliza un vector a longitud unitaria (magnitud = 1).</p> <p>Par\u00e1metros:</p> <ul> <li><code>vec</code>: Vector 3D <code>{x, y, z}</code></li> </ul> <p>Retorna: Vector normalizado <code>{x', y', z'}</code> con \\(|\\mathbf{v}| = 1\\)</p> <p>F\u00f3rmula:</p> \\[ \\hat{\\mathbf{v}} = \\frac{\\mathbf{v}}{|\\mathbf{v}|} = \\frac{\\mathbf{v}}{\\sqrt{v_x^2 + v_y^2 + v_z^2}} \\] <p>Ejemplo: <pre><code>local v = {3, 4, 0}\nlocal vnorm = vec.normalize(v)\n-- vnorm = {0.6, 0.8, 0}\n-- Longitud: sqrt(0.6^2 + 0.8^2) = 1.0\n\nlocal cero = {0, 0, 0}\nlocal cero_norm = vec.normalize(cero)\n-- cero_norm = {0, 0, 0} (caso especial)\n</code></pre></p> <p>Nota: Si el vector es nulo (longitud 0), retorna <code>{0, 0, 0}</code> para evitar divisi\u00f3n por cero.</p>"},{"location":"api_vectores/#operaciones-de-matrices","title":"Operaciones de Matrices","text":""},{"location":"api_vectores/#vecmat3_mulmat1-mat2","title":"<code>vec.mat3_mul(mat1, mat2)</code>","text":"<p>Multiplica dos matrices 3\u00d73.</p> <p>Par\u00e1metros:</p> <ul> <li><code>mat1</code>: Matriz 3\u00d73 <code>{{fila1}, {fila2}, {fila3}}</code></li> <li><code>mat2</code>: Matriz 3\u00d73</li> </ul> <p>Retorna: Matriz 3\u00d73 resultado de \\(C = A \\times B\\)</p> <p>F\u00f3rmula:</p> \\[ C_{ij} = \\sum_{k=1}^{3} A_{ik} \\cdot B_{kj} \\] <p>Ejemplo: <pre><code>local A = {\n  {1, 0, 0},\n  {0, 1, 0},\n  {0, 0, 1}\n}  -- Matriz identidad\n\nlocal B = {\n  {2, 0, 0},\n  {0, 3, 0},\n  {0, 0, 4}\n}  -- Matriz escala\n\nlocal C = vec.mat3_mul(A, B)\n-- C = B (porque A es identidad)\n</code></pre></p> <p>\u26a0\ufe0f Importante: La multiplicaci\u00f3n de matrices NO es conmutativa: \\(A \\times B \\neq B \\times A\\) en general.</p>"},{"location":"api_vectores/#vecmat3_vecvec-mat","title":"<code>vec.mat3_vec(vec, mat)</code>","text":"<p>Multiplica una matriz 3\u00d73 por un vector 3D.</p> <p>Par\u00e1metros:</p> <ul> <li><code>vec</code>: Vector 3D <code>{x, y, z}</code></li> <li><code>mat</code>: Matriz 3\u00d73</li> </ul> <p>Retorna: Vector transformado \\(\\mathbf{v}' = M \\times \\mathbf{v}\\)</p> <p>F\u00f3rmula:</p> \\[ \\begin{pmatrix} v'_x \\\\ v'_y \\\\ v'_z \\end{pmatrix} = \\begin{pmatrix} m_{11} &amp; m_{12} &amp; m_{13} \\\\ m_{21} &amp; m_{22} &amp; m_{23} \\\\ m_{31} &amp; m_{32} &amp; m_{33} \\end{pmatrix} \\begin{pmatrix} v_x \\\\ v_y \\\\ v_z \\end{pmatrix} \\] <p>Ejemplo: <pre><code>-- Rotar vector (1, 0, 0) 90\u00b0 sobre eje Z\nlocal v = {1, 0, 0}\nlocal Rz = vec.rota_z(math.pi/2)  -- 90 grados\nlocal v_rotado = vec.mat3_vec(v, Rz)\n-- v_rotado \u2248 {0, 1, 0}\n</code></pre></p>"},{"location":"api_vectores/#matrices-de-rotacion","title":"Matrices de Rotaci\u00f3n","text":""},{"location":"api_vectores/#vecrota_xangle","title":"<code>vec.rota_x(angle)</code>","text":"<p>Genera matriz de rotaci\u00f3n alrededor del eje X (pitch).</p> <p>Par\u00e1metros:</p> <ul> <li><code>angle</code>: \u00c1ngulo en radianes</li> </ul> <p>Retorna: Matriz 3\u00d73 de rotaci\u00f3n \\(R_x(\\theta)\\)</p> <p>F\u00f3rmula:</p> \\[ R_x(\\theta) = \\begin{pmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; \\cos\\theta &amp; -\\sin\\theta \\\\ 0 &amp; \\sin\\theta &amp; \\cos\\theta \\end{pmatrix} \\] <p>Ejemplo: <pre><code>-- Rotar 45 grados sobre eje X\nlocal Rx = vec.rota_x(math.pi/4)\nlocal v = {0, 1, 0}\nlocal v_rot = vec.mat3_vec(v, Rx)\n-- v_rot \u2248 {0, 0.707, 0.707}\n</code></pre></p> <p>Visualizaci\u00f3n:</p> <pre><code>Eje X (no cambia): \u2192\nPlano YZ rota:\n\n     Y              Y\n     \u2191       \u2192      \u2197\n     |              /\n     +--\u2192 Z    \u03b8   +--\u2192 Z\n</code></pre>"},{"location":"api_vectores/#vecrota_yangle","title":"<code>vec.rota_y(angle)</code>","text":"<p>Genera matriz de rotaci\u00f3n alrededor del eje Y (yaw).</p> <p>Par\u00e1metros:</p> <ul> <li><code>angle</code>: \u00c1ngulo en radianes</li> </ul> <p>Retorna: Matriz 3\u00d73 de rotaci\u00f3n \\(R_y(\\theta)\\)</p> <p>F\u00f3rmula:</p> \\[ R_y(\\theta) = \\begin{pmatrix} \\cos\\theta &amp; 0 &amp; \\sin\\theta \\\\ 0 &amp; 1 &amp; 0 \\\\ -\\sin\\theta &amp; 0 &amp; \\cos\\theta \\end{pmatrix} \\] <p>Ejemplo: <pre><code>-- Girar c\u00e1mara 30 grados a la derecha\nlocal yaw = vec.rota_y(math.rad(30))\n</code></pre></p> <p>Visualizaci\u00f3n:</p> <pre><code>Eje Y (no cambia): \u2191\nPlano XZ rota:\n\n  Z              Z\n  \u2191       \u2192      \u2197\n  |              /\n  +--\u2192 X    \u03b8   +--\u2192 X\n</code></pre>"},{"location":"api_vectores/#vecrota_zangle","title":"<code>vec.rota_z(angle)</code>","text":"<p>Genera matriz de rotaci\u00f3n alrededor del eje Z (roll).</p> <p>Par\u00e1metros:</p> <ul> <li><code>angle</code>: \u00c1ngulo en radianes</li> </ul> <p>Retorna: Matriz 3\u00d73 de rotaci\u00f3n \\(R_z(\\theta)\\)</p> <p>F\u00f3rmula:</p> \\[ R_z(\\theta) = \\begin{pmatrix} \\cos\\theta &amp; -\\sin\\theta &amp; 0 \\\\ \\sin\\theta &amp; \\cos\\theta &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>Ejemplo: <pre><code>-- Rotar sprite 2D 90 grados\nlocal Rz = vec.rota_z(math.pi/2)\n</code></pre></p> <p>Visualizaci\u00f3n:</p> <pre><code>Eje Z (no cambia): \u2299 (saliendo de la pantalla)\nPlano XY rota:\n\n  Y              Y\n  \u2191       \u2192      \u2197\n  |              /\n  +--\u2192 X    \u03b8   +--\u2192 X\n</code></pre>"},{"location":"api_vectores/#vecrotacion_completaanglex-angley-anglez","title":"<code>vec.rotacion_completa(anglex, angley, anglez)</code>","text":"<p>Compone rotaciones de Euler en el orden Z-Y-X.</p> <p>Par\u00e1metros:</p> <ul> <li><code>anglex</code>: \u00c1ngulo sobre X (pitch) en radianes</li> <li><code>angley</code>: \u00c1ngulo sobre Y (yaw) en radianes</li> <li><code>anglez</code>: \u00c1ngulo sobre Z (roll) en radianes</li> </ul> <p>Retorna: Matriz 3\u00d73 compuesta \\(R = R_z(\\gamma) \\times R_y(\\beta) \\times R_x(\\alpha)\\)</p> <p>F\u00f3rmula:</p> \\[ R_{\\text{total}} = R_z(\\gamma) \\cdot R_y(\\beta) \\cdot R_x(\\alpha) \\] <p>Orden de aplicaci\u00f3n (de derecha a izquierda):</p> <ol> <li>Primero rota sobre X (pitch)</li> <li>Luego rota sobre Y (yaw)</li> <li>Finalmente rota sobre Z (roll)</li> </ol> <p>Ejemplo: <pre><code>-- Orientaci\u00f3n completa de un objeto\nlocal pitch = math.rad(15)  -- Inclinar 15\u00b0 hacia arriba\nlocal yaw = math.rad(45)    -- Girar 45\u00b0 a la derecha\nlocal roll = math.rad(0)    -- Sin inclinaci\u00f3n lateral\n\nlocal R = vec.rotacion_completa(pitch, yaw, roll)\nlocal v = {1, 0, 0}\nlocal v_rot = vec.mat3_vec(v, R)\n</code></pre></p> <p>\u26a0\ufe0f Gimbal Lock:</p> <p>Las rotaciones de Euler sufren de \"gimbal lock\" cuando el \u00e1ngulo Y est\u00e1 cerca de \u00b190\u00b0. En ese caso, las rotaciones X y Z se vuelven dependientes.</p> <p>Alternativa: Usar cuaterniones para rotaciones libres de gimbal lock.</p>"},{"location":"api_vectores/#vectransposem","title":"<code>vec.transpose(M)</code>","text":"<p>Calcula la transpuesta de una matriz 3\u00d73.</p> <p>Par\u00e1metros:</p> <ul> <li><code>M</code>: Matriz 3\u00d73</li> </ul> <p>Retorna: Matriz transpuesta \\(M^T\\)</p> <p>F\u00f3rmula:</p> \\[ (M^T)_{ij} = M_{ji} \\] <p>La transpuesta intercambia filas por columnas:</p> \\[ \\begin{pmatrix} a &amp; b &amp; c \\\\ d &amp; e &amp; f \\\\ g &amp; h &amp; i \\end{pmatrix}^T = \\begin{pmatrix} a &amp; d &amp; g \\\\ b &amp; e &amp; h \\\\ c &amp; f &amp; i \\end{pmatrix} \\] <p>Ejemplo: <pre><code>local M = {\n  {1, 2, 3},\n  {4, 5, 6},\n  {7, 8, 9}\n}\n\nlocal MT = vec.transpose(M)\n-- MT = {\n--   {1, 4, 7},\n--   {2, 5, 8},\n--   {3, 6, 9}\n-- }\n</code></pre></p> <p>Uso especial: Para matrices de rotaci\u00f3n (ortonormales), la transpuesta es igual a la inversa:</p> \\[ R^T = R^{-1} \\] <p>Esto permite calcular la inversa de forma eficiente (\\(O(9)\\) en lugar de \\(O(27)\\)).</p> <p>Ejemplo de uso en c\u00e1mara: <pre><code>-- Crear matriz de rotaci\u00f3n de c\u00e1mara\nlocal Rcam = vec.mat3_mul(vec.rota_y(yaw), vec.rota_x(pitch))\n\n-- Calcular inversa (para transformar mundo \u2192 c\u00e1mara)\nlocal Rcam_inv = vec.transpose(Rcam)  -- Eficiente!\n</code></pre></p>"},{"location":"api_vectores/#convenciones","title":"Convenciones","text":""},{"location":"api_vectores/#sistema-de-coordenadas","title":"Sistema de Coordenadas","text":"<p>El rasterizador usa un sistema de coordenadas mano derecha (right-handed):</p> <pre><code>      Y (arriba)\n      \u2191\n      |\n      |\n      +-----\u2192 X (derecha)\n     /\n    /\n   Z (hacia la c\u00e1mara)\n</code></pre> <p>Regla de la mano derecha:</p> <ul> <li>Dedo \u00edndice: +X</li> <li>Dedo medio: +Y</li> <li>Pulgar: +Z</li> </ul>"},{"location":"api_vectores/#angulos","title":"\u00c1ngulos","text":"<ul> <li>Todos los \u00e1ngulos est\u00e1n en radianes</li> <li>Para convertir de grados: <code>radianes = math.rad(grados)</code></li> <li>Para convertir a grados: <code>grados = math.deg(radianes)</code></li> </ul> <p>Conversiones comunes:</p> Grados Radianes Valor aproximado 0\u00b0 0 0 30\u00b0 \u03c0/6 0.524 45\u00b0 \u03c0/4 0.785 60\u00b0 \u03c0/3 1.047 90\u00b0 \u03c0/2 1.571 180\u00b0 \u03c0 3.142 360\u00b0 2\u03c0 6.283"},{"location":"api_vectores/#representacion-de-datos","title":"Representaci\u00f3n de Datos","text":"<p>Vectores: <pre><code>local v = {x, y, z}\n-- Acceso:\nlocal x = v[1]\nlocal y = v[2]\nlocal z = v[3]\n</code></pre></p> <p>Matrices 3\u00d73: <pre><code>local M = {\n  {m11, m12, m13},  -- Fila 1\n  {m21, m22, m23},  -- Fila 2\n  {m31, m32, m33}   -- Fila 3\n}\n\n-- Acceso:\nlocal elemento = M[fila][columna]\n</code></pre></p>"},{"location":"api_vectores/#ejemplos-completos","title":"Ejemplos Completos","text":""},{"location":"api_vectores/#ejemplo-1-rotar-un-cubo","title":"Ejemplo 1: Rotar un Cubo","text":"<pre><code>local vec = require(\"vectors\")\n\n-- Definir v\u00e9rtices de un cubo\nlocal vertices = {\n  {-1, -1, -1}, {1, -1, -1}, {1, 1, -1}, {-1, 1, -1},\n  {-1, -1,  1}, {1, -1,  1}, {1, 1,  1}, {-1, 1,  1}\n}\n\n-- Crear matriz de rotaci\u00f3n\nlocal angulo = math.rad(45)\nlocal R = vec.rotacion_completa(angulo, angulo, 0)\n\n-- Rotar todos los v\u00e9rtices\nlocal vertices_rotados = {}\nfor i, v in ipairs(vertices) do\n  vertices_rotados[i] = vec.mat3_vec(v, R)\nend\n</code></pre>"},{"location":"api_vectores/#ejemplo-2-orientar-objeto-hacia-un-punto","title":"Ejemplo 2: Orientar Objeto hacia un Punto","text":"<pre><code>local vec = require(\"vectors\")\n\n-- Posici\u00f3n del objeto y del objetivo\nlocal pos_objeto = {0, 0, 0}\nlocal pos_objetivo = {10, 5, 3}\n\n-- Vector direcci\u00f3n\nlocal direccion = {\n  pos_objetivo[1] - pos_objeto[1],\n  pos_objetivo[2] - pos_objeto[2],\n  pos_objetivo[3] - pos_objeto[3]\n}\n\n-- Normalizar para obtener vector unitario\nlocal dir_norm = vec.normalize(direccion)\n\n-- Calcular \u00e1ngulos (simplificado)\nlocal yaw = math.atan2(dir_norm[1], dir_norm[3])\nlocal pitch = math.asin(-dir_norm[2])\n\n-- Crear matriz de rotaci\u00f3n\nlocal R = vec.rotacion_completa(pitch, yaw, 0)\n</code></pre>"},{"location":"api_vectores/#ejemplo-3-crear-sistema-de-coordenadas-local","title":"Ejemplo 3: Crear Sistema de Coordenadas Local","text":"<pre><code>local vec = require(\"vectors\")\n\n-- Definir orientaci\u00f3n\nlocal forward = {0, 0, 1}  -- Hacia adelante\nlocal up = {0, 1, 0}       -- Arriba\n\n-- Calcular vector derecha (cross product manual)\nlocal function cross(a, b)\n  return {\n    a[2]*b[3] - a[3]*b[2],\n    a[3]*b[1] - a[1]*b[3],\n    a[1]*b[2] - a[2]*b[1]\n  }\nend\n\nlocal right = vec.normalize(cross(forward, up))\nlocal up_corrected = vec.normalize(cross(right, forward))\n\n-- Construir matriz de cambio de base\nlocal M = {\n  {right[1], right[2], right[3]},\n  {up_corrected[1], up_corrected[2], up_corrected[3]},\n  {-forward[1], -forward[2], -forward[3]}\n}\n</code></pre>"},{"location":"api_vectores/#performance","title":"Performance","text":""},{"location":"api_vectores/#complejidad-computacional","title":"Complejidad Computacional","text":"Operaci\u00f3n Complejidad Operaciones <code>dot</code> O(3) 3 mult + 2 sum <code>normalize</code> O(6) 3 cuad + 1 sqrt + 3 div <code>mat3_vec</code> O(9) 9 mult + 6 sum <code>mat3_mul</code> O(27) 27 mult + 18 sum <code>rota_x/y/z</code> O(2) 1 cos + 1 sin <code>transpose</code> O(9) 9 asignaciones"},{"location":"api_vectores/#optimizaciones","title":"Optimizaciones","text":"<ol> <li>Pre-calcular rotaciones: Si una matriz de rotaci\u00f3n se usa m\u00faltiples veces, calcularla una sola vez.</li> </ol> <pre><code>-- Lento (recalcula cada frame)\nfor i = 1, 1000 do\n  local R = vec.rota_y(angle)\n  -- usar R...\nend\n\n-- R\u00e1pido (calcula una vez)\nlocal R = vec.rota_y(angle)\nfor i = 1, 1000 do\n  -- usar R...\nend\n</code></pre> <ol> <li> <p>Evitar normalizaci\u00f3n innecesaria: Si un vector ya est\u00e1 normalizado, no normalizarlo de nuevo.</p> </li> <li> <p>Usar transpuesta en lugar de inversa: Para matrices ortonormales.</p> </li> </ol>"},{"location":"api_vectores/#referencias","title":"Referencias","text":"<ul> <li>Implementaci\u00f3n: <code>lua/vectors.lua</code></li> <li>Matem\u00e1ticas: <code>docs/matematicas.md</code></li> <li>Ejemplos de uso: <code>lua/main.lua</code></li> </ul> <p>\ud83d\udcdd Nota: Este m\u00f3dulo est\u00e1 optimizado para claridad educativa. Para aplicaciones de producci\u00f3n, considerar usar bibliotecas especializadas como CPML o glm-lua.</p>"},{"location":"explanation/assembly/","title":"Triangle Assembly","text":"<p>How do we convert 3D model data into triangles ready for rasterization? This is the critical bridge between loading a model file and rendering it on screen.</p>"},{"location":"explanation/assembly/#the-model-to-triangle-problem","title":"The Model-to-Triangle Problem","text":"<p>3D models are typically stored as two arrays:</p> <ul> <li>Vertices: A list of 3D points in world space</li> <li>Faces: A list of polygons, each referencing vertex indices</li> </ul> <p>But rasterizers can only draw triangles\u2014three-sided polygons with specific properties that make them efficient to render.</p> <p>The challenge: Convert arbitrary N-sided polygons into triangles while preserving geometry, depth, and color.</p>"},{"location":"explanation/assembly/#model-data-structure","title":"Model Data Structure","text":""},{"location":"explanation/assembly/#vertices","title":"Vertices","text":"<p>Vertices are stored as an array of 3D coordinates:</p> <pre><code>vertices = {\n  {0.0, 0.0, 0.0},    -- Vertex 1\n  {1.0, 0.0, 0.0},    -- Vertex 2\n  {1.0, 1.0, 0.0},    -- Vertex 3\n  {0.0, 1.0, 0.0},    -- Vertex 4\n  ...\n}\n</code></pre> <p>Each vertex is a point in 3D space: \\((x, y, z)\\).</p>"},{"location":"explanation/assembly/#faces","title":"Faces","text":"<p>Faces are stored as arrays of vertex indices:</p> <pre><code>faces = {\n  {1, 2, 3},           -- Triangle (3 vertices)\n  {4, 5, 6, 7},        -- Quad (4 vertices)\n  {8, 9, 10, 11, 12},  -- Pentagon (5 vertices)\n  ...\n}\n</code></pre> <p>Why indices? Vertices are shared between faces\u2014a vertex can be part of multiple polygons. Storing indices instead of duplicating coordinates saves memory.</p> <p>Example:</p> <ul> <li>Face <code>{1, 2, 3}</code> uses vertices at positions 1, 2, and 3 in the <code>vertices</code> array</li> <li>In Lua (1-based indexing): <code>vertices[1]</code>, <code>vertices[2]</code>, <code>vertices[3]</code></li> </ul>"},{"location":"explanation/assembly/#the-triangle-fan-algorithm","title":"The Triangle Fan Algorithm","text":"<p>How do we split an N-sided polygon into triangles?</p>"},{"location":"explanation/assembly/#the-problem","title":"The Problem","text":"<p>A face with N vertices needs to become multiple triangles. How many? N - 2 triangles.</p> <p>Examples: - Triangle (N=3): \\(3 - 2 = 1\\) triangle \u2713 (already a triangle) - Quad (N=4): \\(4 - 2 = 2\\) triangles \u2713 - Pentagon (N=5): \\(5 - 2 = 3\\) triangles \u2713</p>"},{"location":"explanation/assembly/#the-solution-triangle-fan","title":"The Solution: Triangle Fan","text":"<p>The triangle fan algorithm is simple:</p> <ol> <li>Choose one vertex as the origin (typically the first vertex)</li> <li>Create triangles by connecting the origin to consecutive pairs of remaining vertices</li> </ol> <p>Visual breakdown for a quad <code>{1, 2, 3, 4}</code>:</p> <pre><code>  4 -------- 3\n  |          |\n  |          |\n  1 -------- 2\n\nTriangle Fan from vertex 1:\n  Triangle A: {1, 2, 3}\n  Triangle B: {1, 3, 4}\n</code></pre> <p></p>"},{"location":"explanation/assembly/#the-algorithm","title":"The Algorithm","text":"<pre><code>local function triangular_fan(face)\n  local origin = face[1]           -- First vertex is the origin\n  local tris = {}\n\n  for i = 1, #face - 2 do\n    tris[i] = { origin, face[i+1], face[i+2] }\n  end\n\n  return tris\nend\n</code></pre> <p>Step-by-step: 1. Origin = <code>face[1]</code> 2. For each consecutive pair <code>(face[i+1], face[i+2])</code>:    - Create triangle: <code>{origin, face[i+1], face[i+2]}</code></p> <p>Example: Pentagon <code>{1, 2, 3, 4, 5}</code></p> <ul> <li>Origin = vertex 1</li> <li>Triangle 1: <code>{1, 2, 3}</code></li> <li>Triangle 2: <code>{1, 3, 4}</code></li> <li>Triangle 3: <code>{1, 4, 5}</code></li> </ul> <p>Result: 3 triangles from 5 vertices \u2713</p>"},{"location":"explanation/assembly/#why-triangle-fan","title":"Why Triangle Fan?","text":"<ul> <li>Simple: Easy to understand and implement</li> <li>Fast: Linear time complexity \\(O(N)\\)</li> <li>Correct: Preserves winding order (CCW vertices \u2192 CCW triangles)</li> <li>General: Works for any convex polygon</li> </ul> <p>Important: This only works correctly for convex polygons (all internal angles &lt; 180\u00b0). For concave polygons, more complex triangulation algorithms are needed.</p>"},{"location":"explanation/assembly/#the-vertex-transformation-pipeline","title":"The Vertex Transformation Pipeline","text":"<p>Before we can assemble triangles, vertices must be transformed from world space to screen space.</p>"},{"location":"explanation/assembly/#transformation-steps","title":"Transformation Steps","text":"<ol> <li>World space \u2192 Camera space (view transform)</li> <li>Apply camera rotation and translation</li> <li> <p>Result: Vertices relative to camera at origin</p> </li> <li> <p>Camera space \u2192 Screen space (projection)</p> </li> <li>Apply perspective projection</li> <li>Result: 2D screen coordinates</li> </ol>"},{"location":"explanation/assembly/#what-we-preserve","title":"What We Preserve","text":"<p>After transformation, we maintain two representations of each vertex:</p> <p>Camera-space vertex: - 3D coordinates \\((x, y, z)\\) - Used for depth (the \\(z\\) component)</p> <p>Screen-space vertex: - 2D coordinates \\((x_{screen}, y_{screen})\\) - Used for rasterization</p> <p>This dual representation is crucial: we need screen positions to draw, but camera-space depth for the z-buffer.</p>"},{"location":"explanation/assembly/#the-gather_tris-function","title":"The gather_tris() Function","text":"<p>The <code>gather_tris()</code> function is the heart of triangle assembly. It combines transformation, triangulation, and validation into a single pipeline.</p>"},{"location":"explanation/assembly/#inputs","title":"Inputs","text":"<pre><code>local function gather_tris(figs, vc_all, vs_all, face_colors)\n</code></pre> <ul> <li>figs: Array of model figures (each has <code>vertices</code> and <code>faces</code>)</li> <li>vc_all: Camera-space vertices (after view transform)</li> <li>vs_all: Screen-space vertices (after projection)</li> <li>face_colors: Per-face color assignments</li> </ul>"},{"location":"explanation/assembly/#outputs","title":"Outputs","text":"<p>An array of triangle structures ready for rasterization:</p> <pre><code>{\n  p1 = {x, y},        -- Screen position of vertex 1\n  p2 = {x, y},        -- Screen position of vertex 2\n  p3 = {x, y},        -- Screen position of vertex 3\n  z1 = depth,         -- Camera-space depth of vertex 1\n  z2 = depth,         -- Camera-space depth of vertex 2\n  z3 = depth,         -- Camera-space depth of vertex 3\n  color = {r, g, b}   -- Face color\n}\n</code></pre> <p>This structure contains everything the rasterizer needs: - Screen positions for drawing - Depths for z-buffer testing - Color for shading</p>"},{"location":"explanation/assembly/#validation-and-clipping","title":"Validation and Clipping","text":"<p>Not all triangles are valid for rendering. We must validate and clip geometry before rasterization.</p>"},{"location":"explanation/assembly/#near-plane-clipping","title":"Near Plane Clipping","text":"<p>Problem: Vertices behind the camera (negative or very small \\(z\\)) cause division by zero in projection.</p> <p>Solution: Reject triangles with any vertex too close to or behind the camera:</p> <pre><code>local near = 0.001\n\nif v1[3] &gt; near and v2[3] &gt; near and v3[3] &gt; near then\n  -- Safe to rasterize (all vertices in front of camera)\nelse\n  -- Discard triangle (at least one vertex behind camera)\nend\n</code></pre> <p>Why 0.001? This is the near plane distance. Anything closer is considered behind the camera.</p>"},{"location":"explanation/assembly/#degeneracy-check","title":"Degeneracy Check","text":"<p>Problem: Vertices that are collinear (form a line, not a triangle) have zero area. Rasterizing them causes division by zero.</p> <p>Solution: Compute the triangle's signed area using the edge function:</p> <pre><code>local A = edge(x1, y1, x2, y2, x3, y3)\n\nif A ~= 0 then\n  -- Valid triangle (non-zero area)\nelse\n  -- Discard (degenerate triangle)\nend\n</code></pre> <p>The edge function computes:</p> \\[ A = (x_2 - x_1)(y_3 - y_1) - (y_2 - y_1)(x_3 - x_1) \\] <p>This is twice the signed area of the triangle: - \\(A &gt; 0\\): Counter-clockwise (CCW) winding - \\(A &lt; 0\\): Clockwise (CW) winding - \\(A = 0\\): Degenerate (collinear vertices)</p> <p>Why validation matters: Without these checks, we'd attempt to rasterize invalid geometry, causing crashes or visual artifacts.</p>"},{"location":"explanation/assembly/#complete-assembly-algorithm","title":"Complete Assembly Algorithm","text":"<p>Here's the full <code>gather_tris()</code> function with all validation and triangulation logic:</p> <pre><code>local function gather_tris(figs, vc_all, vs_all, face_colors)\n  local tris = {}\n  local near = 0.001\n\n  -- For each model figure\n  for i, fig in ipairs(figs) do\n    local vertices_c = vc_all[i]  -- Camera-space vertices\n    local vertices_s = vs_all[i]  -- Screen-space vertices\n\n    -- For each face in the figure\n    for j, face in ipairs(fig.faces) do\n      -- Split face into triangles using triangle fan\n      local face_tris = triangular_fan(face)\n\n      -- For each triangle in the fan\n      for _, tri in ipairs(face_tris) do\n        local idx1, idx2, idx3 = tri[1], tri[2], tri[3]\n\n        -- Get camera-space vertices (for depth)\n        local v1 = vertices_c[idx1]\n        local v2 = vertices_c[idx2]\n        local v3 = vertices_c[idx3]\n\n        -- Near plane clipping\n        if v1[3] &gt; near and v2[3] &gt; near and v3[3] &gt; near then\n          -- Get screen-space positions\n          local p1 = vertices_s[idx1]\n          local p2 = vertices_s[idx2]\n          local p3 = vertices_s[idx3]\n\n          -- Degeneracy check\n          local A = edge(p1[1], p1[2], p2[1], p2[2], p3[1], p3[2])\n\n          if A ~= 0 then\n            -- Get face color\n            local col = face_colors[i][j]\n\n            -- Store complete triangle\n            tris[#tris + 1] = {\n              p1 = p1, p2 = p2, p3 = p3,\n              z1 = v1[3], z2 = v2[3], z3 = v3[3],\n              color = col\n            }\n          end\n        end\n      end\n    end\n  end\n\n  return tris\nend\n</code></pre>"},{"location":"explanation/assembly/#algorithm-summary","title":"Algorithm Summary","text":"<ol> <li>Iterate over all model figures and faces</li> <li>Triangulate each face using triangle fan</li> <li>Validate each triangle:</li> <li>Check near plane clipping (all vertices \\(z &gt; 0.001\\))</li> <li>Check degeneracy (non-zero area)</li> <li>Package valid triangles with screen positions, depths, and color</li> <li>Return array of renderable triangles</li> </ol>"},{"location":"explanation/assembly/#the-complete-pipeline","title":"The Complete Pipeline","text":"<p>From loading a 3D model to rendering it on screen, here's the full pipeline:</p>"},{"location":"explanation/assembly/#step-1-load-model","title":"Step 1: Load Model","text":"<p>Read vertices and faces from file:</p> <pre><code>model = {\n  vertices = { {x1,y1,z1}, {x2,y2,z2}, ... },\n  faces = { {1,2,3}, {4,5,6,7}, ... }\n}\n</code></pre>"},{"location":"explanation/assembly/#step-2-assign-colors","title":"Step 2: Assign Colors","text":"<p>Determine per-face colors from material properties:</p> <pre><code>face_colors = {\n  {r1, g1, b1},  -- Color for face 1\n  {r2, g2, b2},  -- Color for face 2\n  ...\n}\n</code></pre>"},{"location":"explanation/assembly/#step-3-view-transform","title":"Step 3: View Transform","text":"<p>Transform vertices from world space to camera space:</p> <p>Input: World-space vertices Transform: Apply camera rotation and translation Output: Camera-space vertices <code>vc_all</code></p> <p>Each vertex now expressed relative to camera at origin.</p>"},{"location":"explanation/assembly/#step-4-projection","title":"Step 4: Projection","text":"<p>Project camera-space vertices to screen space:</p> <p>Input: Camera-space vertices <code>vc_all</code> Transform: Apply perspective projection Output: Screen-space vertices <code>vs_all</code></p> <p>Each vertex now has 2D screen coordinates.</p>"},{"location":"explanation/assembly/#step-5-triangle-assembly","title":"Step 5: Triangle Assembly","text":"<p>Call <code>gather_tris()</code> to create renderable triangles:</p> <p>Input: Models, camera-space vertices, screen-space vertices, colors Process: 1. Triangulate faces using triangle fan 2. Validate triangles (near plane + degeneracy) 3. Package: <code>{screen_pos, depth, color}</code></p> <p>Output: Array of complete triangles ready for rasterization</p>"},{"location":"explanation/assembly/#step-6-rasterization","title":"Step 6: Rasterization","text":"<p>Draw triangles using the z-buffer algorithm:</p> <ul> <li>For each pixel in triangle:</li> <li>Interpolate depth using barycentric coordinates</li> <li>Z-test: is this pixel closer than what's stored?</li> <li>If yes: update z-buffer and draw pixel</li> </ul>"},{"location":"explanation/assembly/#example-walkthrough","title":"Example Walkthrough","text":"<p>Let's trace a simple quad through the entire pipeline.</p>"},{"location":"explanation/assembly/#given","title":"Given","text":"<p>Vertices (world space): <pre><code>v1 = {0, 0, 5}\nv2 = {1, 0, 5}\nv3 = {1, 1, 5}\nv4 = {0, 1, 5}\n</code></pre></p> <p>Face: <code>{1, 2, 3, 4}</code> (quad, CCW winding)</p> <p>Color: <code>{1.0, 0.5, 0.0}</code> (orange)</p>"},{"location":"explanation/assembly/#step-1-triangle-fan","title":"Step 1: Triangle Fan","text":"<p>Split the quad into two triangles:</p> <ul> <li>Origin = vertex 1</li> <li>Triangle A: <code>{1, 2, 3}</code></li> <li>Triangle B: <code>{1, 3, 4}</code></li> </ul>"},{"location":"explanation/assembly/#step-2-transform-to-camera-space","title":"Step 2: Transform to Camera Space","text":"<p>Assume identity camera (camera at origin, no rotation):</p> <pre><code>vc1 = {0, 0, 5}\nvc2 = {1, 0, 5}\nvc3 = {1, 1, 5}\nvc4 = {0, 1, 5}\n</code></pre> <p>The vertices are already in camera space.</p>"},{"location":"explanation/assembly/#step-3-project-to-screen","title":"Step 3: Project to Screen","text":"<p>Assume FOV = 60\u00b0, screen resolution = 800\u00d7600.</p> <p>Calculate focal length:</p> \\[ f = \\frac{height / 2}{\\tan(FOV / 2)} = \\frac{300}{\\tan(30\u00b0)} \\approx 519.6 \\] <p>Project each vertex:</p> <p>For vertex 1: \\((0, 0, 5)\\)</p> \\[ \\begin{aligned} x_{proj} &amp;= f \\times \\frac{0}{5} = 0 \\\\ y_{proj} &amp;= f \\times \\frac{0}{5} = 0 \\\\ x_{screen} &amp;= 0 + 400 = 400 \\\\ y_{screen} &amp;= 300 - 0 = 300 \\end{aligned} \\] <p>Result: vs1 = <code>{400, 300}</code> (screen center)</p> <p>For vertex 2: \\((1, 0, 5)\\)</p> \\[ \\begin{aligned} x_{proj} &amp;= 519.6 \\times \\frac{1}{5} = 103.9 \\\\ y_{proj} &amp;= 519.6 \\times \\frac{0}{5} = 0 \\\\ x_{screen} &amp;= 103.9 + 400 = 503.9 \\\\ y_{screen} &amp;= 300 - 0 = 300 \\end{aligned} \\] <p>Result: vs2 = <code>{503.9, 300}</code></p> <p>Similarly: - vs3 \u2248 <code>{503.9, 196.1}</code> - vs4 \u2248 <code>{400, 196.1}</code></p>"},{"location":"explanation/assembly/#step-4-assemble-triangles","title":"Step 4: Assemble Triangles","text":"<p>Create triangle structures:</p> <p>Triangle A: <code>{1, 2, 3}</code></p> <pre><code>{\n  p1 = {400, 300},\n  p2 = {503.9, 300},\n  p3 = {503.9, 196.1},\n  z1 = 5,\n  z2 = 5,\n  z3 = 5,\n  color = {1.0, 0.5, 0.0}\n}\n</code></pre> <p>Triangle B: <code>{1, 3, 4}</code></p> <pre><code>{\n  p1 = {400, 300},\n  p2 = {503.9, 196.1},\n  p3 = {400, 196.1},\n  z1 = 5,\n  z2 = 5,\n  z3 = 5,\n  color = {1.0, 0.5, 0.0}\n}\n</code></pre>"},{"location":"explanation/assembly/#step-5-validation","title":"Step 5: Validation","text":"<p>Near plane check: All depths = 5 &gt; 0.001 \u2713</p> <p>Degeneracy check: Both triangles have non-zero area \u2713</p>"},{"location":"explanation/assembly/#step-6-ready-for-rasterization","title":"Step 6: Ready for Rasterization!","text":"<p>Both triangles pass validation and are added to the <code>tris[]</code> array, ready to be drawn on screen.</p>"},{"location":"explanation/assembly/#why-this-approach","title":"Why This Approach?","text":"<p>The triangle assembly system has several key advantages:</p>"},{"location":"explanation/assembly/#flexibility","title":"Flexibility","text":"<p>Handles any N-sided polygon\u2014triangles, quads, pentagons, or more complex shapes\u2014all using the same triangle fan algorithm.</p>"},{"location":"explanation/assembly/#efficiency","title":"Efficiency","text":"<p>Triangle fan is computationally cheap: \\(O(N)\\) time complexity for an N-sided polygon.</p>"},{"location":"explanation/assembly/#correctness","title":"Correctness","text":"<p>Preserves winding order: CCW vertices produce CCW triangles, ensuring correct backface culling and normal orientation.</p>"},{"location":"explanation/assembly/#modularity","title":"Modularity","text":"<p>Clean separation of concerns: - Transformation: Convert to camera/screen space - Assembly: Create triangles - Validation: Ensure renderable geometry - Rasterization: Draw pixels</p> <p>Each stage has a clear input and output, making the pipeline easy to understand and debug.</p>"},{"location":"explanation/assembly/#memory-efficiency","title":"Memory Efficiency","text":"<p>Vertices are stored once and referenced by index\u2014shared vertices don't duplicate data.</p>"},{"location":"explanation/assembly/#summary","title":"Summary","text":"<p>Triangle assembly is the bridge between 3D model data and renderable triangles.</p> <p>Key Insights:</p> <ul> <li>Models store vertices (3D points) + faces (index lists)</li> <li>Triangle fan splits N-sided polygons into N-2 triangles</li> <li>gather_tris() combines transformation, triangulation, and validation</li> <li>Output structure: <code>{screen_pos, depth, color}</code> \u2014 everything needed for rasterization</li> <li>Near plane clipping prevents rendering geometry behind the camera</li> <li>Degeneracy check prevents invalid triangles with zero area</li> </ul> <p>What We Achieved:</p> <ul> <li>\u2705 Convert arbitrary polygons to triangles</li> <li>\u2705 Preserve depth information for z-buffer</li> <li>\u2705 Validate geometry before rasterization</li> <li>\u2705 Create a clean pipeline from model data to renderable triangles</li> </ul> <p>The Formula:</p> <p>For an N-sided polygon:</p> \\[ \\text{Number of triangles} = N - 2 \\] <p>Edge function (signed area):</p> \\[ A = (x_2 - x_1)(y_3 - y_1) - (y_2 - y_1)(x_3 - x_1) \\] <p>Near plane test:</p> \\[ z &gt; 0.001 \\] <p>With triangle assembly complete, our 3D models are now ready for the z-buffer and rasterization stages!</p>"},{"location":"explanation/camera/","title":"Camera and Movement","text":"<p>How do we move and rotate a 3D camera? This is essential for creating an interactive 3D experience where the user can explore the scene.</p> <p></p>"},{"location":"explanation/camera/#camera-orientation-yaw-and-pitch","title":"Camera Orientation: Yaw and Pitch","text":"<p>A 3D camera has several rotational degrees of freedom:</p> <ul> <li>Yaw: Rotation around the Y-axis (vertical) \u2014 turns the camera left and right</li> <li>Pitch: Rotation around the X-axis (horizontal) \u2014 tilts the camera up and down</li> <li>Roll: Rotation around the Z-axis (forward) \u2014 we'll ignore this for now</li> </ul> <p>In this rasterizer, we use yaw and pitch to control camera orientation, giving us a first-person camera system.</p>"},{"location":"explanation/camera/#understanding-yaw-rotation","title":"Understanding Yaw Rotation","text":"<p>Let's start with yaw \u2014 the horizontal rotation that turns the camera left and right.</p>"},{"location":"explanation/camera/#the-unit-circle-view","title":"The Unit Circle View","text":"<p>When we rotate around the Y-axis, the Y coordinate doesn't change (height stays the same). We're only rotating in the XZ plane.</p> <p></p> <p>Looking down from above (the XZ plane), we can think of this as a unit circle:</p> <ul> <li>The right vector starts at \\((1, 0, 0)\\) \u2014 pointing in the \\(+X\\) direction</li> <li>The forward vector starts at \\((0, 0, 1)\\) \u2014 pointing in the \\(+Z\\) direction</li> </ul>"},{"location":"explanation/camera/#rotating-by-angle","title":"Rotating by Angle \u03b8","text":"<p>If we rotate these vectors by an angle \\(\\theta\\) (yaw):</p> <ul> <li>Right vector becomes: \\((\\cos\\theta, y, \\sin\\theta)\\)</li> <li>Forward vector becomes: \\((-\\sin\\theta, y, \\cos\\theta)\\)</li> </ul>"},{"location":"explanation/camera/#applying-to-any-point","title":"Applying to Any Point","text":"<p>For a general 3D point \\((x, y, z)\\) rotated by yaw angle \\(\\theta\\):</p> \\[ \\begin{aligned} x' &amp;= \\cos(\\theta) \\cdot x + \\sin(\\theta) \\cdot z \\\\ y' &amp;= y \\\\ z' &amp;= -\\sin(\\theta) \\cdot x + \\cos(\\theta) \\cdot z \\end{aligned} \\] <p>Key insight: The Y component stays unchanged because yaw only rotates around the Y-axis.</p>"},{"location":"explanation/camera/#rotation-matrices","title":"Rotation Matrices","text":"<p>We can represent this rotation more compactly using matrix notation.</p>"},{"location":"explanation/camera/#expressing-points-as-column-vectors","title":"Expressing Points as Column Vectors","text":"<p>A 3D point \\((x, y, z)\\) can be written as a column vector:</p> \\[ \\mathbf{v} = \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} \\]"},{"location":"explanation/camera/#yaw-rotation-matrix","title":"Yaw Rotation Matrix","text":"<p>The yaw rotation can be expressed as a \\(3 \\times 3\\) matrix:</p> \\[ R_y(\\theta) = \\begin{bmatrix} \\cos\\theta &amp; 0 &amp; \\sin\\theta \\\\ 0 &amp; 1 &amp; 0 \\\\ -\\sin\\theta &amp; 0 &amp; \\cos\\theta \\end{bmatrix} \\] <p>Matrix-vector multiplication gives the same result as our formulas:</p> \\[ \\begin{bmatrix} x' \\\\ y' \\\\ z' \\end{bmatrix} = R_y(\\theta) \\cdot \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} \\] <p>Expanding this multiplication:</p> \\[ \\begin{bmatrix} x' \\\\ y' \\\\ z' \\end{bmatrix} = \\begin{bmatrix} \\cos\\theta \\cdot x + \\sin\\theta \\cdot z \\\\ y \\\\ -\\sin\\theta \\cdot x + \\cos\\theta \\cdot z \\end{bmatrix} \\] <p>This matches our rotation formulas exactly!</p>"},{"location":"explanation/camera/#pitch-rotation-matrix","title":"Pitch Rotation Matrix","text":"<p>Using the same technique for pitch (rotation around the X-axis), we get:</p> \\[ R_x(\\phi) = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; \\cos\\phi &amp; -\\sin\\phi \\\\ 0 &amp; \\sin\\phi &amp; \\cos\\phi \\end{bmatrix} \\] <p>Where \\(\\phi\\) is the pitch angle.</p>"},{"location":"explanation/camera/#combined-camera-rotation","title":"Combined Camera Rotation","text":"<p>To represent the full camera orientation, we combine both rotations into a single matrix.</p>"},{"location":"explanation/camera/#the-camera-rotation-matrix","title":"The Camera Rotation Matrix","text":"\\[ R_{cam} = R_y(\\text{yaw}) \\times R_x(\\text{pitch}) \\] <p>Important: The order matters! Matrix multiplication is not commutative:</p> \\[ R_y \\times R_x \\neq R_x \\times R_y \\] <p>We apply yaw first, then pitch. This matches the intuitive behavior of a first-person camera.</p>"},{"location":"explanation/camera/#extracting-camera-axes","title":"Extracting Camera Axes","text":"<p>The resulting \\(R_{cam}\\) matrix has a useful property: its columns represent the camera's local coordinate axes:</p> \\[ R_{cam} = \\begin{bmatrix} | &amp; | &amp; | \\\\ \\text{right} &amp; \\text{up} &amp; \\text{forward} \\\\ | &amp; | &amp; | \\end{bmatrix} \\] <ul> <li>1st column: Right vector (camera's local X-axis)</li> <li>2nd column: Up vector (camera's local Y-axis)</li> <li>3rd column: Forward vector (camera's local Z-axis)</li> </ul> <p>These vectors tell us which direction the camera is facing in world space.</p>"},{"location":"explanation/camera/#free-fly-movement","title":"Free-Fly Movement","text":"<p>Now that we have the camera's orientation, we can implement movement.</p>"},{"location":"explanation/camera/#extracting-direction-vectors","title":"Extracting Direction Vectors","text":"<p>From the camera rotation matrix \\(R_{cam}\\), we extract:</p> <pre><code>local right   = { Rcam[1][1], Rcam[2][1], Rcam[3][1] }  -- 1st column\nlocal forward = { Rcam[1][3], Rcam[2][3], Rcam[3][3] }  -- 3rd column\n</code></pre>"},{"location":"explanation/camera/#movement-update","title":"Movement Update","text":"<p>To move the camera in a direction, we update its position:</p> <p>Moving forward:</p> \\[ \\begin{aligned} cam_x &amp;= cam_x + forward_x \\cdot speed \\cdot \\Delta t \\\\ cam_y &amp;= cam_y + forward_y \\cdot speed \\cdot \\Delta t \\\\ cam_z &amp;= cam_z + forward_z \\cdot speed \\cdot \\Delta t \\end{aligned} \\] <p>Strafing right:</p> \\[ \\begin{aligned} cam_x &amp;= cam_x + right_x \\cdot speed \\cdot \\Delta t \\\\ cam_y &amp;= cam_y + right_y \\cdot speed \\cdot \\Delta t \\\\ cam_z &amp;= cam_z + right_z \\cdot speed \\cdot \\Delta t \\end{aligned} \\] <p>Where \\(\\Delta t\\) is the time elapsed since the last frame (delta time).</p>"},{"location":"explanation/camera/#free-fly-mode","title":"Free-Fly Mode","text":"<p>This gives us free-fly movement \u2014 the camera can move in any direction, including up and down. It's not locked to the ground plane like a walking character would be.</p> <p>For example, if you pitch the camera upward and press forward, you'll fly upward into the sky!</p>"},{"location":"explanation/camera/#point-transformation-before-projection","title":"Point Transformation Before Projection","text":"<p>Before we can project a 3D point to the screen, we need to transform it into camera space.</p>"},{"location":"explanation/camera/#step-1-translate-to-camera-relative-coordinates","title":"Step 1: Translate to Camera-Relative Coordinates","text":"<p>First, express the point relative to the camera's position:</p> \\[ \\mathbf{p}_{rel} = \\mathbf{p}_{world} - \\mathbf{cam.pos} \\] <p>This moves the camera to the origin \\((0, 0, 0)\\).</p>"},{"location":"explanation/camera/#step-2-the-naive-approach-doesnt-work","title":"Step 2: The Naive Approach (Doesn't Work!)","text":"<p>You might think we should rotate the point using \\(R_{cam}\\):</p> \\[ \\mathbf{p}_{camera} = R_{cam} \\times \\mathbf{p}_{rel} \\quad \\text{\u274c WRONG!} \\] <p>Why doesn't this work?</p> <p>When the camera moves to the right, objects in the scene should appear to move left on the screen. Similarly, when the camera looks up, objects should move down on screen.</p> <p>The world rotates in the opposite direction of the camera!</p>"},{"location":"explanation/camera/#step-3-the-correct-approach-inverse-rotation","title":"Step 3: The Correct Approach \u2014 Inverse Rotation","text":"<p>We need to multiply by the inverse of the camera rotation:</p> \\[ \\mathbf{p}_{camera} = R_{cam}^{-1} \\times \\mathbf{p}_{rel} \\] <p>Key property: For rotation matrices, the inverse equals the transpose:</p> \\[ R_{cam}^{-1} = R_{cam}^T \\] <p>This is because rotation matrices are orthogonal (their columns are perpendicular unit vectors).</p>"},{"location":"explanation/camera/#the-complete-transformation","title":"The Complete Transformation","text":"<p>Putting it together:</p> \\[ \\mathbf{p}_{camera} = R_{cam}^T \\times (\\mathbf{p}_{world} - \\mathbf{cam.pos}) \\] <p>Remember: The order of operations matters! We translate first, then rotate.</p>"},{"location":"explanation/camera/#complete-algorithm","title":"Complete Algorithm","text":"<p>Here's how the full camera transformation works in code:</p> <pre><code>-- Step 1: Build the camera rotation matrices\nlocal function build_cam_mats()\n  local Ry = rota_y(cam.yaw)         -- Yaw rotation matrix\n  local Rx = rota_x(cam.pitch)       -- Pitch rotation matrix\n  local Rcam = mat3_mul(Ry, Rx)      -- Combined: Rcam = Ry \u00d7 Rx\n  local RcamT = transpose(Rcam)      -- Inverse rotation (transpose)\n  return Rcam, RcamT\nend\n\n-- Step 2: Extract movement directions\nlocal Rcam, RcamT = build_cam_mats()\nlocal right   = { Rcam[1][1], Rcam[2][1], Rcam[3][1] }\nlocal forward = { Rcam[1][3], Rcam[2][3], Rcam[3][3] }\n\n-- Step 3: Update camera position based on input\nlocal speed = 1.5\nif love.keyboard.isDown(\"w\") then\n  cam.pos.x = cam.pos.x + forward[1] * speed * dt\n  cam.pos.y = cam.pos.y + forward[2] * speed * dt\n  cam.pos.z = cam.pos.z + forward[3] * speed * dt\nend\n\n-- Step 4: Transform world point to camera space\nlocal function transform_to_camera_space(point_world, cam, RcamT)\n  -- Translate to camera-relative coordinates\n  local rel = {\n    point_world[1] - cam.pos.x,\n    point_world[2] - cam.pos.y,\n    point_world[3] - cam.pos.z\n  }\n\n  -- Apply inverse camera rotation (transpose)\n  local point_camera = mat3_vec(rel, RcamT)\n\n  return point_camera\nend\n\n-- Step 5: Project to screen (from previous chapter)\nlocal function project_to_screen(point_camera, fov, width, height)\n  local x, y, z = point_camera[1], point_camera[2], point_camera[3]\n\n  if z &lt;= 0.001 then return nil end  -- Behind camera\n\n  local f = (height / 2.0) / math.tan(math.rad(fov) / 2.0)\n  local x_proj = f * (x / z)\n  local y_proj = f * (y / z)\n\n  local x_screen = x_proj + (width / 2.0)\n  local y_screen = (height / 2.0) - y_proj\n\n  return x_screen, y_screen\nend\n</code></pre>"},{"location":"explanation/camera/#summary","title":"Summary","text":"<p>The camera transformation pipeline:</p> <ol> <li>Build rotation matrices from yaw and pitch angles</li> <li>Combine them: \\(R_{cam} = R_y(\\text{yaw}) \\times R_x(\\text{pitch})\\)</li> <li>Extract direction vectors from \\(R_{cam}\\) columns for movement</li> <li>Transform points to camera space: \\(R_{cam}^T \\times (\\mathbf{p}_{world} - \\mathbf{cam.pos})\\)</li> <li>Project to screen using perspective projection</li> </ol> <p>Key insights:</p> <ul> <li>Yaw rotates around Y-axis (left/right)</li> <li>Pitch rotates around X-axis (up/down)</li> <li>Matrix columns give us the camera's local axes (right, up, forward)</li> <li>We use the transpose (inverse) of \\(R_{cam}\\) to transform points correctly</li> <li>Matrix multiplication order matters</li> </ul> <p>With this camera system, we can now freely navigate our 3D scene and view it from any angle!</p> <p>Next: We'll explore the Z-buffer algorithm for correctly sorting overlapping triangles by depth.</p>"},{"location":"explanation/projection/","title":"Basics of 3D Projection","text":"<p>How do we project a 3D point onto a 2D screen? This is the fundamental question that every 3D renderer must answer.</p> <p></p>"},{"location":"explanation/projection/#the-projection-problem","title":"The Projection Problem","text":"<p>We have: - A camera at position \\((c_x, c_y, c_z)\\) - A 3D point in world space at \\((x_1, y_1, z_1)\\) - A 2D screen (image plane) where we want to draw</p> <p>Our goal: Find the 2D coordinates \\((x_{screen}, y_{screen})\\) where this 3D point appears on the screen.</p>"},{"location":"explanation/projection/#the-perspective-projection-model","title":"The Perspective Projection Model","text":"<p>In perspective projection, we simulate how a real camera works:</p> <ol> <li>Light from a 3D point travels through a projection center (the camera)</li> <li>It intersects with an image plane (the screen)</li> <li>Where it intersects is where we draw the pixel</li> </ol>"},{"location":"explanation/projection/#key-components","title":"Key Components","text":"<ul> <li>Projection Center: The camera position (a single point in 3D space)</li> <li>Image Plane: The virtual screen positioned at distance \\(f\\) from the camera</li> <li>Focal Length (\\(f\\)): The distance from the camera to the image plane</li> <li>Field of View (FOV): How \"wide\" the camera can see (measured in degrees)</li> </ul> <p>Note: Traditional graphics use a near plane and far plane for clipping, but in our implementation, we use the near plane as our image plane for simplicity.</p>"},{"location":"explanation/projection/#field-of-view-fov","title":"Field of View (FOV)","text":"<p>The FOV determines how much of the scene the camera can see:</p> <ul> <li>Narrow FOV (e.g., 30\u00b0): Telephoto lens, zoomed in, little distortion</li> <li>Normal FOV (e.g., 60\u00b0): Human-like vision</li> <li>Wide FOV (e.g., 90\u00b0+): Wide-angle lens, fisheye effect</li> </ul> <p>Relationship: The FOV and focal length are inversely related\u2014wider FOV means shorter focal length.</p>"},{"location":"explanation/projection/#step-1-transform-to-camera-space","title":"Step 1: Transform to Camera Space","text":"<p>Before projection, we must move the camera to the origin \\((0, 0, 0)\\). This simplifies the math.</p>"},{"location":"explanation/projection/#world-space-camera-space","title":"World Space \u2192 Camera Space","text":"<p>For a 3D point \\((x_{world}, y_{world}, z_{world})\\) and camera at \\((c_x, c_y, c_z)\\):</p> \\[ \\begin{aligned} x_{rel} &amp;= x_{world} - c_x \\\\ y_{rel} &amp;= y_{world} - c_y \\\\ z_{rel} &amp;= z_{world} - c_z \\end{aligned} \\] <p>Now the point is expressed relative to the camera, which we treat as the origin.</p>"},{"location":"explanation/projection/#step-2-calculate-focal-length","title":"Step 2: Calculate Focal Length","text":"<p>The focal length (\\(f\\)) is computed from the FOV and screen dimensions.</p>"},{"location":"explanation/projection/#the-formula","title":"The Formula","text":"<p>For the vertical axis:</p> \\[ \\tan\\left(\\frac{FOV}{2}\\right) = \\frac{height / 2}{f} \\] <p>Solving for \\(f\\):</p> \\[ f = \\frac{height / 2}{\\tan(FOV / 2)} \\]"},{"location":"explanation/projection/#why-this-works","title":"Why This Works","text":"<ul> <li>At distance \\(f\\) from the camera, the image plane has height exactly equal to <code>height</code> pixels</li> <li>The FOV determines the viewing angle, which relates to the ratio \\(\\frac{height}{f}\\)</li> <li>Larger FOV \u2192 smaller \\(f\\) \u2192 more distortion (wide angle)</li> <li>Smaller FOV \u2192 larger \\(f\\) \u2192 less distortion (telephoto)</li> </ul>"},{"location":"explanation/projection/#horizontal-focal-length","title":"Horizontal Focal Length","text":"<p>To maintain aspect ratio, we set:</p> \\[ f_x = f_y = f \\] <p>This ensures circles stay circular and squares stay square.</p>"},{"location":"explanation/projection/#step-3-project-to-screen-coordinates","title":"Step 3: Project to Screen Coordinates","text":"<p>Now we apply the perspective division\u2014the heart of perspective projection.</p>"},{"location":"explanation/projection/#the-projection-formulas","title":"The Projection Formulas","text":"<p>For a 3D point \\((x_{rel}, y_{rel}, z_{rel})\\) in camera space:</p> \\[ \\begin{aligned} x_{proj} &amp;= f \\times \\frac{x_{rel}}{z_{rel}} \\\\ y_{proj} &amp;= f \\times \\frac{y_{rel}}{z_{rel}} \\end{aligned} \\] <p>Key insight: We divide by \\(z\\)! This is why distant objects appear smaller\u2014larger \\(z\\) makes the result smaller.</p>"},{"location":"explanation/projection/#why-division-by-z","title":"Why Division by Z?","text":"<p>Consider two points at the same \\(x\\) but different depths:</p> <ul> <li>Point A: \\((x=1, z=2)\\) \u2192 \\(x_{proj} = f \\times \\frac{1}{2} = 0.5f\\)</li> <li>Point B: \\((x=1, z=4)\\) \u2192 \\(x_{proj} = f \\times \\frac{1}{4} = 0.25f\\)</li> </ul> <p>Point B is twice as far, so it appears half the size\u2014this is perspective!</p>"},{"location":"explanation/projection/#step-4-convert-to-pixel-coordinates","title":"Step 4: Convert to Pixel Coordinates","text":"<p>The projected coordinates \\((x_{proj}, y_{proj})\\) are centered at the optical center of the camera, where \\((0, 0)\\) is the middle of the screen.</p> <p>But in screen coordinates, \\((0, 0)\\) is the top-left corner. We need to shift:</p> \\[ \\begin{aligned} x_{screen} &amp;= x_{proj} + \\frac{width}{2} \\\\ y_{screen} &amp;= \\frac{height}{2} - y_{proj} \\end{aligned} \\] <p>Note the minus sign for \\(y\\)! In camera space, \\(+y\\) points up. In screen space, \\(+y\\) points down.</p>"},{"location":"explanation/projection/#complete-projection-algorithm","title":"Complete Projection Algorithm","text":"<p>Putting it all together:</p> <pre><code>function project_point_to_screen(point_world, camera, fov, width, height)\n    -- Step 1: Transform to camera space\n    local x_rel = point_world.x - camera.x\n    local y_rel = point_world.y - camera.y\n    local z_rel = point_world.z - camera.z\n\n    -- Step 2: Calculate focal length\n    local fov_rad = math.rad(fov)\n    local f = (height / 2.0) / math.tan(fov_rad / 2.0)\n\n    -- Step 3: Project (perspective division)\n    local x_proj = f * (x_rel / z_rel)\n    local y_proj = f * (y_rel / z_rel)\n\n    -- Step 4: Convert to screen coordinates\n    local x_screen = x_proj + (width / 2.0)\n    local y_screen = (height / 2.0) - y_proj\n\n    return x_screen, y_screen\nend\n</code></pre>"},{"location":"explanation/projection/#important-edge-cases","title":"Important Edge Cases","text":""},{"location":"explanation/projection/#points-behind-the-camera","title":"Points Behind the Camera","text":"<p>If \\(z_{rel} \\leq 0\\), the point is behind the camera and should not be drawn.</p> <p>We use a near plane threshold:</p> <pre><code>local near = 0.001\nif z_rel &gt; near then\n    -- Safe to project\nelse\n    -- Discard (behind camera or too close)\nend\n</code></pre>"},{"location":"explanation/projection/#points-outside-screen","title":"Points Outside Screen","text":"<p>After projection, check if the point is visible:</p> <pre><code>if x_screen &gt;= 0 and x_screen &lt; width and\n   y_screen &gt;= 0 and y_screen &lt; height then\n    -- Point is on screen\nend\n</code></pre>"},{"location":"explanation/projection/#summary","title":"Summary","text":"<p>Perspective projection in 4 steps:</p> <ol> <li>Transform to camera space: Subtract camera position</li> <li>Calculate focal length: From FOV and screen size</li> <li>Perspective division: Divide by \\(z\\) to get projected coordinates</li> <li>Convert to pixels: Shift origin from center to top-left corner</li> </ol> <p>The key insight: Division by \\(z\\) creates perspective\u2014distant objects appear smaller because we divide by a larger number.</p> <p>Next: We'll use this projection to build a complete 3D rasterizer with camera controls!</p>"},{"location":"explanation/rasterization/","title":"Simple Rasterization in LOVE","text":"<p>The goal of this tutorial is to draw a simple triangle using rasterization in L\u00d6VE2D. We'll build everything from scratch to understand how pixels are actually drawn on screen.</p> <p></p>"},{"location":"explanation/rasterization/#part-1-creating-the-software-buffer","title":"Part 1: Creating the Software Buffer","text":"<p>Before we can draw anything, we need a place to store pixel data. In L\u00d6VE2D, we'll create a software framebuffer using <code>ImageData</code>:</p> <pre><code>local W, H = 320, 180\nlocal imgData, img\n\nfunction love.load()\n    imgData = love.image.newImageData(W, H)\n    img     = love.graphics.newImage(imgData)\n    img:setFilter(\"nearest\", \"nearest\")\n\n    -- Clear to black\n    imgData:mapPixel(function() return 0, 0, 0, 1 end)\nend\n</code></pre>"},{"location":"explanation/rasterization/#whats-happening-here","title":"What's happening here?","text":"<ul> <li><code>imgData</code>: This is the buffer\u2014think of it as a box that stores the color of every pixel (320\u00d7180 = 57,600 pixels)</li> <li><code>img</code>: This is the representation of that buffer that L\u00d6VE can display on screen</li> <li><code>setFilter(\"nearest\", \"nearest\")</code>: Prevents blurring when scaling up</li> <li><code>mapPixel</code>: Sets all pixels to black (RGB: 0,0,0, Alpha: 1)</li> </ul> <p>The buffer is where we'll manually write pixels. Once we're done, we'll tell L\u00d6VE to update the image with <code>img:replacePixels(imgData)</code>.</p>"},{"location":"explanation/rasterization/#part-2-defining-the-triangle","title":"Part 2: Defining the Triangle","text":"<p>Let's define a triangle with 3 vertices:</p> <pre><code>local p1 = { 40,  30 }   -- Top-left\nlocal p2 = { 280, 50 }   -- Top-right\nlocal p3 = { 120, 150 }  -- Bottom\n</code></pre>"},{"location":"explanation/rasterization/#the-challenge-drawing-all-pixels-inside","title":"The Challenge: Drawing All Pixels Inside","text":"<p>How do we know which pixels are inside the triangle? We can't just draw the edges\u2014we need to fill the entire interior.</p> <p>The answer: Vector mathematics and CCW (Counter-Clockwise) winding order.</p>"},{"location":"explanation/rasterization/#mathematical-foundation","title":"Mathematical Foundation","text":"<p>Key insight: A point \\(P\\) is inside a convex polygon if and only if it lies on the same side of all edges.</p> <p>For a triangle with vertices ordered counter-clockwise \\((v_1, v_2, v_3)\\):</p> <ul> <li>Point \\(P\\) is inside if it's to the right of edge \\(v_1 \\to v_2\\)</li> <li>And to the right of edge \\(v_2 \\to v_3\\)</li> <li>And to the right of edge \\(v_3 \\to v_1\\)</li> </ul> <p>But how do we determine \"left\" vs \"right\"? We use the 2D cross product (also called the edge function).</p>"},{"location":"explanation/rasterization/#the-edge-function","title":"The Edge Function","text":"<p>For an edge from \\((x_0, y_0)\\) to \\((x_1, y_1)\\) and a test point \\((x, y)\\):</p> \\[ E(x, y) = (x - x_0)(y_1 - y_0) - (y - y_0)(x_1 - x_0) \\] <p>This formula computes the signed area of the parallelogram formed by vectors \\((P - P_0)\\) and \\((P_1 - P_0)\\).</p> <p>Interpretation:</p> <ul> <li>\\(E(x, y) &gt; 0\\) \u2192 Point is to the left of the edge</li> <li>\\(E(x, y) &lt; 0\\) \u2192 Point is to the right of the edge</li> <li>\\(E(x, y) = 0\\) \u2192 Point is on the edge</li> </ul> <p>Interesting property: \\(E(x, y)\\) equals twice the area of triangle \\((P_0, P_1, P)\\)!</p> \\[ \\text{Area}(\\triangle P_0 P_1 P) = \\frac{|E(x, y)|}{2} \\]"},{"location":"explanation/rasterization/#part-3-the-edge-function-implementation","title":"Part 3: The Edge Function Implementation","text":"<pre><code>local function edge(x0, y0, x1, y1, x, y)\n    return (x - x0)*(y1 - y0) - (y - y0)*(x1 - x0)\nend\n</code></pre> <p>This simple function is the heart of rasterization. It tells us:</p> <ol> <li>Whether a point is inside the triangle</li> <li>The barycentric coordinates for interpolation (more on this later)</li> <li>The signed area of sub-triangles</li> </ol>"},{"location":"explanation/rasterization/#part-4-the-clamp-helper-function","title":"Part 4: The Clamp Helper Function","text":"<p>Before we rasterize, we need a helper to keep coordinates within bounds:</p> <pre><code>local function clamp(x, a, b)\n    if x &lt; a then return a\n    elseif x &gt; b then return b\n    else return x\n    end\nend\n</code></pre> <p>Why? We don't want to test every pixel on the screen\u2014only those in the triangle's bounding box.</p>"},{"location":"explanation/rasterization/#part-5-triangle-rasterization-function","title":"Part 5: Triangle Rasterization Function","text":"<p>Now let's build the complete rasterization function step by step:</p> <pre><code>local function fill_triangle2D(imgData, W, H, p1, p2, p3, color)\n    local x1, y1 = p1[1], p1[2]\n    local x2, y2 = p2[1], p2[2]\n    local x3, y3 = p3[1], p3[2]\n    local r, g, b, a = color[1], color[2], color[3], color[4] or 1\n</code></pre>"},{"location":"explanation/rasterization/#step-1-calculate-triangle-area","title":"Step 1: Calculate Triangle Area","text":"<pre><code>    -- Oriented area\n    local A = edge(x1, y1, x2, y2, x3, y3)\n    if A == 0 then return end  -- Degenerate triangle (collapsed to a line)\n    local invA = 1.0 / A\n</code></pre> <p>Why store <code>invA</code> (inverse area)?</p> <p>We'll multiply by <code>invA</code> many times in the inner loop. Multiplication is faster than division, so we pre-compute \\(\\frac{1}{A}\\) once instead of dividing by \\(A\\) thousands of times.</p> \\[ \\frac{E(P)}{A} = E(P) \\times \\frac{1}{A} \\] <p>Performance impact: In a 320\u00d7180 buffer, we might test ~10,000+ pixels. Avoiding division saves significant time!</p>"},{"location":"explanation/rasterization/#step-2-compute-bounding-box","title":"Step 2: Compute Bounding Box","text":"<pre><code>    -- Bounding box\n    local minx = clamp(math.floor(math.min(x1, x2, x3)), 0, W-1)\n    local maxx = clamp(math.floor(math.max(x1, x2, x3)), 0, W-1)\n    local miny = clamp(math.floor(math.min(y1, y2, y3)), 0, H-1)\n    local maxy = clamp(math.floor(math.max(y1, y2, y3)), 0, H-1)\n</code></pre> <p>Instead of testing all 57,600 pixels in a 320\u00d7180 buffer, we only test pixels in the smallest rectangle that contains the triangle. This optimization can save ~98% of pixel tests!</p>"},{"location":"explanation/rasterization/#step-3-test-each-pixel","title":"Step 3: Test Each Pixel","text":"<pre><code>    -- Iterate over pixels (using pixel center)\n    for y = miny, maxy do\n        for x = minx, maxx do\n            local px, py = x + 0.5, y + 0.5\n</code></pre> <p>Why <code>x + 0.5</code> and <code>y + 0.5</code>?</p> <p>Pixels are actually squares, not points. Testing at the pixel center (0.5, 0.5) gives more accurate results and matches how GPUs sample.</p> <pre><code>Pixel at (10, 20):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       \u2502\n\u2502   \u2022   \u2502  \u2190 We test here (10.5, 20.5)\n\u2502       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n (10,20)\n</code></pre>"},{"location":"explanation/rasterization/#step-4-compute-barycentric-coordinates","title":"Step 4: Compute Barycentric Coordinates","text":"<pre><code>            local w1 = edge(x2, y2, x3, y3, px, py) * invA\n            local w2 = edge(x3, y3, x1, y1, px, py) * invA\n            local w3 = 1.0 - w1 - w2\n</code></pre> <p>These are barycentric coordinates\u2014they express point \\(P\\) as a weighted combination of the three vertices:</p> \\[ P = w_1 \\cdot v_1 + w_2 \\cdot v_2 + w_3 \\cdot v_3 \\] <p>where \\(w_1 + w_2 + w_3 = 1\\).</p> <p>Properties:</p> <ul> <li>\\(w_1, w_2, w_3 \\in [0, 1]\\) \u2192 Point is inside the triangle</li> <li>Any weight \\(&lt; 0\\) or \\(&gt; 1\\) \u2192 Point is outside</li> </ul> <p>Visual explanation:</p> <pre><code>       v1\n       *\n      /|\\\n   w1/ | \\w2\n    /  |  \\\n   /   \u2022P  \\     P = w1*v1 + w2*v2 + w3*v3\n  /  w3|    \\\n *\u2500\u2500\u2500\u2500\u2500|\u2500\u2500\u2500\u2500\u2500*\nv3           v2\n</code></pre>"},{"location":"explanation/rasterization/#step-5-inside-test-and-drawing","title":"Step 5: Inside Test and Drawing","text":"<pre><code>            if w1&gt;=0 and w2&gt;=0 and w3&gt;=0 then\n                imgData:setPixel(x, y, r, g, b, a)\n            end\n</code></pre> <p>The CCW Rule:</p> <p>A point is inside the triangle if all three barycentric coordinates are non-negative:</p> <ul> <li>\\(w_1 \\geq 0\\) \u2192 Point is to the right of edge \\(v_2 \\to v_3\\)</li> <li>\\(w_2 \\geq 0\\) \u2192 Point is to the right of edge \\(v_3 \\to v_1\\)</li> <li>\\(w_3 \\geq 0\\) \u2192 Point is to the right of edge \\(v_1 \\to v_2\\)</li> </ul> <p>Important: Our triangles must be defined in CCW (counter-clockwise) order for this test to work correctly. If vertices are in CW order, the test will fail and nothing will be drawn.</p>"},{"location":"explanation/rasterization/#part-6-putting-it-all-together","title":"Part 6: Putting It All Together","text":"<pre><code>function love.load()\n    love.window.setTitle(\"2D Triangle - Basic Rasterizer\")\n    imgData = love.image.newImageData(W, H)\n    img     = love.graphics.newImage(imgData)\n    img:setFilter(\"nearest\", \"nearest\")\n\n    -- Clear to black\n    imgData:mapPixel(function() return 0, 0, 0, 1 end)\n\n    -- Define triangle (screen coordinates)\n    local p1 = { 40,  30 }\n    local p2 = { 280, 50 }\n    local p3 = { 120, 150 }\n\n    -- Rasterize!\n    fill_triangle2D(imgData, W, H, p1, p2, p3, {1, 0.6, 0.1, 1})\n\n    -- Update the image\n    img:replacePixels(imgData)\nend\n\nfunction love.draw()\n    local winW, winH = love.graphics.getDimensions()\n    love.graphics.draw(img, 0, 0, 0, winW/W, winH/H)\nend\n</code></pre>"},{"location":"explanation/rasterization/#execution-flow","title":"Execution Flow","text":"<ol> <li>love.load(): Initialize buffer \u2192 Draw triangle \u2192 Update image</li> <li>love.draw(): Display the image scaled to window size</li> </ol>"},{"location":"explanation/rasterization/#summary","title":"Summary","text":"<p>We've built a complete 2D triangle rasterizer using:</p> <ol> <li>Software framebuffer (<code>ImageData</code>) to store pixels</li> <li>Edge function to test if points are inside the triangle</li> <li>Barycentric coordinates for precise inside/outside testing</li> <li>Bounding box optimization to avoid testing every screen pixel</li> <li>Pixel center sampling for accuracy</li> </ol> <p>This is the fundamental algorithm used in all 3D graphics! GPUs do the exact same thing, just with:</p> <ul> <li>Hardware acceleration (parallel processing)</li> <li>Depth testing (z-buffer)</li> <li>Texture mapping</li> <li>Perspective correction</li> </ul> <p>Next, we'll extend this to 3D by adding projection and depth buffering!</p>"},{"location":"explanation/zbuffer/","title":"Z-Buffer","text":"<p>How do we determine which triangle is in front when multiple objects overlap? This is the visibility problem that every 3D renderer must solve.</p> <p></p>"},{"location":"explanation/zbuffer/#the-depth-problem","title":"The Depth Problem","text":"<p>Consider two triangles in 3D space that overlap when viewed from the camera:</p> <ul> <li>Triangle A is closer to the camera (smaller z)</li> <li>Triangle B is farther away (larger z)</li> </ul> <p>Question: Which triangle should appear in front on the screen?</p>"},{"location":"explanation/zbuffer/#without-a-z-buffer","title":"Without a Z-Buffer","text":"<p>If we simply draw triangles in the order they appear in our data:</p> <ul> <li>Draw Triangle B first \u2192 fills pixels</li> <li>Draw Triangle A second \u2192 overwrites those pixels \u2705</li> </ul> <p>This works! But what if the order is reversed?</p> <ul> <li>Draw Triangle A first \u2192 fills pixels</li> <li>Draw Triangle B second \u2192 overwrites Triangle A \u274c WRONG!</li> </ul> <p>Problem: Rendering order determines visibility, not actual depth. We'd need to sort all triangles by depth before drawing\u2014expensive and error-prone.</p>"},{"location":"explanation/zbuffer/#with-a-z-buffer","title":"With a Z-Buffer","text":"<p>The z-buffer solves this automatically:</p> <ul> <li>For each pixel, store its depth (distance from camera)</li> <li>Before drawing a pixel, check: \"Is this fragment closer than what's already there?\"</li> <li>If yes: draw and update depth</li> <li>If no: discard (don't draw)</li> </ul> <p>Result: Triangles can be drawn in any order, and the closest one always wins!</p>"},{"location":"explanation/zbuffer/#what-is-a-z-buffer","title":"What is a Z-Buffer?","text":"<p>The z-buffer is a 2D array that stores a depth value for every pixel on the screen.</p> <p></p>"},{"location":"explanation/zbuffer/#data-structure","title":"Data Structure","text":"<p>In this rasterizer, the z-buffer is implemented as a 1D Lua table:</p> <pre><code>zbuf = {}  -- One depth value per pixel\n</code></pre> <p>For a screen resolution of 820\u00d7580 pixels, the buffer contains 475,600 depth values.</p>"},{"location":"explanation/zbuffer/#array-indexing","title":"Array Indexing","text":"<p>Pixels are stored in row-major order (row by row, left to right):</p> \\[ idx = y \\times width + x + 1 \\] <p>Why the +1? Lua uses 1-based indexing (arrays start at index 1, not 0).</p> <p>Example: - Pixel at (5, 10) in a 820-pixel-wide buffer:   - <code>idx = 10 \u00d7 820 + 5 + 1 = 8206</code></p>"},{"location":"explanation/zbuffer/#initialization","title":"Initialization","text":"<p>Every pixel starts with depth = infinity (as far away as possible):</p> <pre><code>for i = 1, RENDER_W * RENDER_H do\n  zbuf[i] = math.huge  -- Lua's representation of infinity\nend\n</code></pre> <p>Why infinity? Any real depth value will be closer, so the first triangle drawn at a pixel will always pass the depth test.</p>"},{"location":"explanation/zbuffer/#the-depth-test","title":"The Depth Test","text":"<p>The core algorithm is simple: only draw if closer.</p>"},{"location":"explanation/zbuffer/#algorithm","title":"Algorithm","text":"<p>For each pixel \\((x, y)\\) we want to draw:</p> <ol> <li>Compute depth <code>z</code> at that pixel (using barycentric interpolation)</li> <li>Get stored depth: <code>depth_stored = zbuf[idx]</code></li> <li>Compare:</li> <li>If <code>z &lt; depth_stored</code>: This fragment is closer<ul> <li>Update z-buffer: <code>zbuf[idx] = z</code></li> <li>Draw pixel with triangle's color</li> </ul> </li> <li>Otherwise: This fragment is farther \u2192 discard (don't draw)</li> </ol>"},{"location":"explanation/zbuffer/#the-depth-test-condition","title":"The Depth Test Condition","text":"\\[ z &lt; zbuf[idx] \\] <p>Interpretation: - Smaller z = closer to camera - Larger z = farther from camera</p> <p>Test meaning: \"Is the new fragment closer than what's currently stored?\"</p>"},{"location":"explanation/zbuffer/#code-example","title":"Code Example","text":"<pre><code>local idx = y * RENDER_W + x + 1\n\nif z &lt; zbuf[idx] then\n  zbuf[idx] = z              -- Update depth\n  imgData:setPixel(x, y, r, g, b, 1)  -- Draw pixel\nend\n</code></pre> <p>As shown in the diagram above, when Triangle 1 is drawn, the z-buffer fills with its depth values. When Triangle 2 is drawn later, only pixels where Triangle 2 is closer get updated\u2014the z-buffer prevents Triangle 2 from overwriting closer pixels from Triangle 1.</p>"},{"location":"explanation/zbuffer/#perspective-correct-depth-interpolation","title":"Perspective-Correct Depth Interpolation","text":"<p>Here's a crucial detail: we cannot simply interpolate \\(z\\) linearly in screen space.</p>"},{"location":"explanation/zbuffer/#the-problem","title":"The Problem","text":"<p>After perspective projection, screen space is non-linear\u2014objects farther away are compressed more than nearby objects.</p> <p>If we linearly interpolate \\(z\\) using barycentric coordinates directly:</p> \\[ z = w_1 \\cdot z_1 + w_2 \\cdot z_2 + w_3 \\cdot z_3 \\quad \\text{\u274c WRONG!} \\] <p>This gives incorrect depth values because barycentric coordinates are linear in screen space, but depth varies non-linearly due to perspective.</p>"},{"location":"explanation/zbuffer/#the-solution-interpolate-1z","title":"The Solution: Interpolate 1/z","text":"<p>The key mathematical insight: reciprocal depth (\\(1/z\\)) varies linearly in screen space!</p> <p>Algorithm: 1. Precompute reciprocals for each vertex:    $\\(invz_i = \\frac{1}{z_i}\\)$</p> <ol> <li> <p>Linearly interpolate \\(1/z\\) using barycentric coordinates:    $\\(invz = w_1 \\cdot invz_1 + w_2 \\cdot invz_2 + w_3 \\cdot invz_3\\)$</p> </li> <li> <p>Recover actual depth:    $\\(z = \\frac{1}{invz}\\)$</p> </li> </ol>"},{"location":"explanation/zbuffer/#why-this-works","title":"Why This Works","text":"<p>Barycentric coordinates \\((w_1, w_2, w_3)\\) are linear in screen space\u2014they change uniformly across the triangle after projection.</p> <p>When we interpolate \\(1/z\\) (instead of \\(z\\)) using these linear weights, we get perspective-correct results because:</p> <ul> <li>The perspective projection maps world-space depth \\(z\\) non-linearly to screen space</li> <li>But \\(1/z\\) transforms linearly through projection</li> <li>Interpolating linearly in screen space and taking the reciprocal recovers the correct world-space depth</li> </ul> <p>This is a fundamental principle of perspective-correct rasterization used in all 3D graphics.</p>"},{"location":"explanation/zbuffer/#barycentric-coordinates-and-depth","title":"Barycentric Coordinates and Depth","text":"<p>Recall from triangle rasterization that barycentric coordinates \\((w_1, w_2, w_3)\\) express a point \\(P\\) as a weighted blend of the three triangle vertices:</p> \\[ P = w_1 \\cdot v_1 + w_2 \\cdot v_2 + w_3 \\cdot v_3 \\] <p>where \\(w_1 + w_2 + w_3 = 1\\).</p>"},{"location":"explanation/zbuffer/#using-barycentric-weights-for-depth","title":"Using Barycentric Weights for Depth","text":"<p>We use these same weights to interpolate depth:</p> <pre><code>-- Precompute reciprocal depths (once per triangle)\nlocal invz1 = 1.0 / T.z1\nlocal invz2 = 1.0 / T.z2\nlocal invz3 = 1.0 / T.z3\n\n-- For each pixel inside the triangle:\nlocal w1 = edge(x2,y2, x3,y3, px,py) * invA\nlocal w2 = edge(x3,y3, x1,y1, px,py) * invA\nlocal w3 = 1.0 - w1 - w2\n\n-- Interpolate 1/z\nlocal invz = w1*invz1 + w2*invz2 + w3*invz3\n\n-- Recover z\nlocal z = 1.0 / invz\n</code></pre>"},{"location":"explanation/zbuffer/#formula-summary","title":"Formula Summary","text":"\\[ \\begin{aligned} invz_1 &amp;= \\frac{1}{z_1}, \\quad invz_2 = \\frac{1}{z_2}, \\quad invz_3 = \\frac{1}{z_3} \\\\[8pt] invz &amp;= w_1 \\cdot invz_1 + w_2 \\cdot invz_2 + w_3 \\cdot invz_3 \\\\[8pt] z &amp;= \\frac{1}{invz} \\end{aligned} \\] <p>Key property: Each barycentric weight represents how much influence the corresponding vertex has on the pixel. Vertices closer to the pixel have larger weights.</p>"},{"location":"explanation/zbuffer/#complete-z-buffer-algorithm","title":"Complete Z-Buffer Algorithm","text":"<p>Putting it all together, here's the full rasterization loop with z-buffering:</p> <pre><code>local function rasterize_with_zbuffer(tris, winW, winH)\n  -- Step 1: Clear z-buffer to infinity\n  for i = 1, RENDER_W * RENDER_H do\n    zbuf[i] = math.huge\n  end\n  imgData:mapPixel(function() return 0, 0, 0, 1 end)\n\n  -- Step 2: Rasterize each triangle\n  for i = 1, #tris do\n    local T = tris[i]\n    local r, g, b = T.color[1], T.color[2], T.color[3]\n\n    -- Transform to render coordinates\n    local sx, sy = RENDER_W / winW, RENDER_H / winH\n    local x1, y1 = T.p1[1]*sx, T.p1[2]*sy\n    local x2, y2 = T.p2[1]*sx, T.p2[2]*sy\n    local x3, y3 = T.p3[1]*sx, T.p3[2]*sy\n\n    -- Compute bounding box\n    local minx = math.max(0, math.floor(math.min(x1,x2,x3)))\n    local maxx = math.min(RENDER_W-1, math.floor(math.max(x1,x2,x3)))\n    local miny = math.max(0, math.floor(math.min(y1,y2,y3)))\n    local maxy = math.min(RENDER_H-1, math.floor(math.max(y1,y2,y3)))\n\n    -- Triangle area and reciprocal depths\n    local A = edge(x1,y1, x2,y2, x3,y3)\n    if A ~= 0 then\n      local invA = 1.0 / A\n      local invz1 = 1.0 / T.z1\n      local invz2 = 1.0 / T.z2\n      local invz3 = 1.0 / T.z3\n\n      -- Step 3: Rasterize pixels in bounding box\n      for y = miny, maxy do\n        for x = minx, maxx do\n          local px, py = x + 0.5, y + 0.5  -- Pixel center\n\n          -- Compute barycentric coordinates\n          local w1 = edge(x2,y2, x3,y3, px,py) * invA\n          local w2 = edge(x3,y3, x1,y1, px,py) * invA\n          local w3 = 1.0 - w1 - w2\n\n          -- Inside-triangle test\n          if w1&gt;=0 and w2&gt;=0 and w3&gt;=0 then\n            -- Perspective-correct depth interpolation\n            local invz = w1*invz1 + w2*invz2 + w3*invz3\n            local z = 1.0 / invz\n\n            -- Z-test\n            local idx = y*RENDER_W + x + 1\n            if z &lt; zbuf[idx] then\n              zbuf[idx] = z\n              imgData:setPixel(x, y, r, g, b, 1)\n            end\n          end\n        end\n      end\n    end\n  end\n\n  img:replacePixels(imgData)\nend\n</code></pre>"},{"location":"explanation/zbuffer/#the-complete-pipeline","title":"The Complete Pipeline","text":"<p>How does depth flow through the rendering pipeline?</p>"},{"location":"explanation/zbuffer/#from-3d-vertex-to-final-pixel","title":"From 3D Vertex to Final Pixel","text":"<ol> <li>World coordinates \u2192 Model transform</li> <li> <p>Object vertices in world space</p> </li> <li> <p>View transform (camera space)</p> </li> <li>Transform relative to camera</li> <li> <p>z value obtained here (distance from camera)</p> </li> <li> <p>Projection to screen space</p> </li> <li>Apply perspective projection</li> <li>Preserve z for later use</li> <li> <p>Vertices become 2D screen positions</p> </li> <li> <p>Triangle assembly</p> </li> <li>Store: <code>(p1, p2, p3, z1, z2, z3, color)</code></li> <li> <p>Screen positions + original depths</p> </li> <li> <p>Rasterization</p> </li> <li> <p>For each pixel in triangle:</p> <ul> <li>Interpolate \\(1/z\\) using barycentric weights</li> <li>Recover \\(z = 1/invz\\)</li> <li>Z-test: <code>if z &lt; zbuf[idx]</code> then draw</li> </ul> </li> <li> <p>Display</p> </li> <li>Only pixels that passed z-test are visible</li> </ol> <p>Key insight: The depth values come from camera space (step 2), but are used during rasterization (step 5) after projection to screen space.</p>"},{"location":"explanation/zbuffer/#edge-cases-and-important-details","title":"Edge Cases and Important Details","text":""},{"location":"explanation/zbuffer/#why-initialize-to-mathhuge","title":"Why Initialize to <code>math.huge</code>?","text":"<p>Using infinity ensures that any real depth value will pass the initial depth test. This way, the first triangle to render at a pixel will always draw.</p>"},{"location":"explanation/zbuffer/#why-test-z-zbufidx-instead-of","title":"Why Test <code>z &lt; zbuf[idx]</code> Instead of <code>&gt;</code>?","text":"<p>In this coordinate system: - Smaller z = closer to camera (in front) - Larger z = farther from camera (behind)</p> <p>The test <code>z &lt; zbuf[idx]</code> means: \"Is this fragment closer than what's currently stored?\"</p>"},{"location":"explanation/zbuffer/#near-plane-clipping","title":"Near Plane Clipping","text":"<p>Before triangles reach rasterization, vertices behind or too close to the camera are rejected:</p> <pre><code>if v1[3] &gt; near and v2[3] &gt; near and v3[3] &gt; near then\n  -- Vertex depths are valid (z &gt; 0.001)\nend\n</code></pre> <p>Vertices with \\(z \\leq 0.001\\) are discarded to prevent division by zero in projection.</p>"},{"location":"explanation/zbuffer/#z-fighting","title":"Z-Fighting","text":"<p>What happens when two triangles have the exact same depth at a pixel?</p> <p>Answer: The first triangle rendered wins (first-come, first-served).</p> <p>This can cause z-fighting\u2014flickering artifacts when two surfaces occupy the same depth. Solutions include: - Increase z-buffer precision - Offset one surface slightly - Use depth bias</p>"},{"location":"explanation/zbuffer/#example-walkthrough","title":"Example Walkthrough","text":"<p>Let's compute depth for a specific pixel step by step.</p>"},{"location":"explanation/zbuffer/#given","title":"Given","text":"<ul> <li>Triangle vertices with depths: \\(z_1 = 2.0\\), \\(z_2 = 3.0\\), \\(z_3 = 4.0\\)</li> <li>Pixel with barycentric coordinates: \\(w_1 = 0.5\\), \\(w_2 = 0.3\\), \\(w_3 = 0.2\\)</li> <li>Z-buffer at this pixel currently stores: \\(zbuf[idx] = 5.0\\)</li> </ul>"},{"location":"explanation/zbuffer/#step-1-precompute-reciprocal-depths","title":"Step 1: Precompute Reciprocal Depths","text":"\\[ \\begin{aligned} invz_1 &amp;= \\frac{1}{2.0} = 0.500 \\\\ invz_2 &amp;= \\frac{1}{3.0} \\approx 0.333 \\\\ invz_3 &amp;= \\frac{1}{4.0} = 0.250 \\end{aligned} \\]"},{"location":"explanation/zbuffer/#step-2-interpolate-1z","title":"Step 2: Interpolate 1/z","text":"\\[ \\begin{aligned} invz &amp;= w_1 \\cdot invz_1 + w_2 \\cdot invz_2 + w_3 \\cdot invz_3 \\\\      &amp;= 0.5 \\times 0.500 + 0.3 \\times 0.333 + 0.2 \\times 0.250 \\\\      &amp;= 0.250 + 0.100 + 0.050 \\\\      &amp;= 0.400 \\end{aligned} \\]"},{"location":"explanation/zbuffer/#step-3-recover-depth","title":"Step 3: Recover Depth","text":"\\[ z = \\frac{1}{invz} = \\frac{1}{0.400} = 2.5 \\]"},{"location":"explanation/zbuffer/#step-4-z-test","title":"Step 4: Z-Test","text":"<p>Compare: \\(z = 2.5\\) vs \\(zbuf[idx] = 5.0\\)</p> <p>Test: \\(2.5 &lt; 5.0\\) \u2192 \u2705 PASS</p> <p>Action: - Update z-buffer: <code>zbuf[idx] = 2.5</code> - Draw pixel with triangle color</p> <p>Result: This fragment is closer than what was stored, so it becomes visible!</p>"},{"location":"explanation/zbuffer/#summary","title":"Summary","text":"<p>The z-buffer solves the visibility problem in 3D rendering:</p> <p>Key Insights:</p> <ul> <li>Z-buffer = 2D array storing depth for each pixel</li> <li>Initialization: All depths start at infinity (<code>math.huge</code>)</li> <li>Depth test: <code>z &lt; zbuf[idx]</code> (closer fragments overwrite farther ones)</li> <li>Perspective-correct interpolation: Use \\(1/z\\) with barycentric weights</li> <li>No sorting needed: Triangles can be drawn in any order</li> </ul> <p>What We Achieved:</p> <ul> <li>\u2705 Correct occlusion \u2014 objects in front hide objects behind</li> <li>\u2705 Any rendering order \u2014 no need to sort triangles by depth</li> <li>\u2705 Automatic visibility \u2014 z-buffer handles overlap without manual intervention</li> </ul> <p>The Formula:</p> \\[ \\begin{aligned} invz &amp;= w_1 \\cdot \\frac{1}{z_1} + w_2 \\cdot \\frac{1}{z_2} + w_3 \\cdot \\frac{1}{z_3} \\\\[6pt] z &amp;= \\frac{1}{invz} \\\\[6pt] \\text{if } z &lt; zbuf[idx] &amp;\\text{ then draw} \\end{aligned} \\] <p>With the z-buffer, our 3D rasterizer can now correctly render complex scenes with overlapping geometry\u2014just like modern GPUs do!</p>"}]}